{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_category_sales = pd.read_csv('../data/daily_category_sales.csv', header=[0,1], index_col=0)\n",
    "quantity_data = daily_category_sales['quantity_sum'].copy()\n",
    "print(quantity_data.isna().sum())\n",
    "quantity_data.fillna(0, inplace=True) # use zero to replace NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LSTM for sales volume prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataset\n",
    "### Use sales quantity of last 30 days to predict sales quantity of next 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([733, 30, 6]) torch.Size([733, 7, 6])\n"
     ]
    }
   ],
   "source": [
    "lag = 30\n",
    "X = np.array([np.array(quantity_data.iloc[idx-lag:idx,]) for idx in range(lag, quantity_data.shape[0]-7, 1)])\n",
    "y = np.array([np.array(quantity_data.iloc[idx:idx+7,]) for idx in range(lag, quantity_data.shape[0]-7, 1)])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "y_val_tensor = torch.FloatTensor(y_val).to(device)\n",
    "print(X_train_tensor.shape, y_train_tensor.shape)\n",
    "# (batch, seq_len, input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure & initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, output_seq_len):\n",
    "        super(MultiLSTM, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size*output_seq_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        output = self.fc(last_output)\n",
    "        output = output.view(output.size(0), output_seq_len, output_size)  # 将输出变形为 (batch_size, m, 7)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LSTM model\n",
    "input_size = 6\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "output_size = 6\n",
    "output_seq_len = 7\n",
    "\n",
    "model = MultiLSTM(input_size, hidden_size, output_size, output_seq_len).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data in batches\n",
    "dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "batch_size = 128\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "n_batch = math.ceil(X_train_tensor.shape[0] / batch_size)\n",
    "\n",
    "train_loss, val_loss = [], [] \n",
    "# train\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = 0\n",
    "    model.train()\n",
    "    for X_batch, y_batch in data_loader:\n",
    "        # forward pass\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        # Compute the RMSE loss\n",
    "        loss = torch.sqrt(criterion(outputs, y_batch))\n",
    "\n",
    "        # backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item() / n_batch\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        epoch_val_loss = torch.sqrt(criterion(val_outputs, y_val_tensor))\n",
    "\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    val_loss.append(epoch_val_loss.item())\n",
    "\n",
    "    if (epoch+1) % 50 == 0 or epoch == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(train_loss, label='Train Loss')\n",
    "ax.plot(val_loss, label='Validation Loss')\n",
    "ax.set_xlabel('Epoch', fontsize=16)\n",
    "ax.set_ylabel('RMSE Loss', fontsize=16)\n",
    "ax.set_title('Train and Validation Loss',fontsize=20)\n",
    "ax.set_ylim(0, 110)\n",
    "ax.legend(fontsize=16)\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('../figures/lstm1_train_val_loss.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"input_size\": input_size,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"output_size\": output_size,\n",
    "    \"fc_size\": 24\n",
    "}\n",
    "\n",
    "with open('../model/lstm1_config.json', 'w') as f:\n",
    "    json.dump(model_config, f)\n",
    "\n",
    "torch.save(model.state_dict(),'../model/lstm1_for_category_sales_volume.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Metrics: R-square & RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "y_pred = model(X_val_tensor).cpu().detach().numpy()\n",
    "y_true = y_val_tensor.cpu().detach().numpy()\n",
    "print(f'R-square: {r2_score(y_true.reshape(-1), y_pred.reshape(-1)):.4f};\\t RMSE: {torch.sqrt(criterion(val_outputs, y_val_tensor)).item():.4f}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Visualize prediction of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights\n",
    "model = MultiLSTM(input_size, hidden_size, output_size, output_seq_len).to(device)\n",
    "model.load_state_dict(torch.load('../model/lstm1_for_category_sales_volume.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.FloatTensor(X).to(device)\n",
    "y_tensor = torch.FloatTensor(y).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_tensor)\n",
    "\n",
    "y_true = y_tensor[:,0,:].cpu().detach().numpy().T \n",
    "y_pred = y_pred_tensor[:,0,:].cpu().detach().numpy().T\n",
    "\n",
    "math.sqrt(mean_squared_error(y_true.reshape(-1), y_pred.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(y_true[0].reshape(-1), label='True')\n",
    "ax.plot(y_pred[0].reshape(-1), label='Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LSTM for wholesale price prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average wholesale price\n",
    "price_data = daily_category_sales['cost_sum'] / daily_category_sales['quantity_sum']\n",
    "price_data.fillna(0, inplace=True) \n",
    "\n",
    "lag = 30\n",
    "X = np.array([np.array(price_data.iloc[idx-lag:idx,]) for idx in range(lag, price_data.shape[0]-7, 1)])\n",
    "y = np.array([np.array(price_data.iloc[idx:idx+7,]) for idx in range(lag, price_data.shape[0]-7, 1)])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "y_val_tensor = torch.FloatTensor(y_val).to(device)\n",
    "print(X_train_tensor.shape, y_train_tensor.shape)\n",
    "# (batch, seq_len, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLSTM(input_size, hidden_size, output_size, output_seq_len).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data in batches\n",
    "dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "batch_size = 128\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "n_batch = math.ceil(X_train_tensor.shape[0] / batch_size)\n",
    "\n",
    "train_loss, val_loss = [], [] \n",
    "# train\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = 0\n",
    "    model.train()\n",
    "    for X_batch, y_batch in data_loader:\n",
    "        # forward pass\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        # Compute the RMSE loss\n",
    "        loss = torch.sqrt(criterion(outputs, y_batch))\n",
    "\n",
    "        # backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item() / n_batch\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        epoch_val_loss = torch.sqrt(criterion(val_outputs, y_val_tensor))\n",
    "\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    val_loss.append(epoch_val_loss.item())\n",
    "\n",
    "    if (epoch+1) % 50 == 0 or epoch == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(train_loss, label='Train Loss')\n",
    "ax.plot(val_loss, label='Validation Loss')\n",
    "ax.set_xlabel('Epoch', fontsize=16)\n",
    "ax.set_ylabel('RMSE Loss', fontsize=16)\n",
    "ax.set_title('Train and Validation Loss',fontsize=20)\n",
    "ax.set_ylim(0, 3)\n",
    "ax.legend(fontsize=16)\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('../figures/lstm2_train_val_loss.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"input_size\": input_size,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"output_size\": output_size,\n",
    "    \"fc_size\": 24\n",
    "}\n",
    "\n",
    "with open('../model/lstm2_config.json', 'w') as f:\n",
    "    json.dump(model_config, f)\n",
    "\n",
    "torch.save(model.state_dict(),'../model/lstm2_for_category_wholesale_price.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Make predictions for the following week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = MultiLSTM(input_size, hidden_size, output_size, output_seq_len).to(device)\n",
    "lstm1.load_state_dict(torch.load('../model/lstm1_for_category_sales_volume.pt'))\n",
    "lstm2 = MultiLSTM(input_size, hidden_size, output_size, output_seq_len).to(device)\n",
    "lstm2.load_state_dict(torch.load('../model/lstm2_for_category_wholesale_price.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X1 = quantity_data.iloc[-lag:,].values.reshape(1, lag, input_size)\n",
    "pred_X1_tensor = torch.FloatTensor(pred_X1).to(device)\n",
    "\n",
    "pred_X2 = price_data.iloc[-lag:,].values.reshape(1, lag, input_size)\n",
    "pred_X2_tensor = torch.FloatTensor(pred_X2).to(device)\n",
    "\n",
    "print(pred_X1_tensor.shape, pred_X2_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred_y1 = lstm1(pred_X1_tensor)\n",
    "    pred_y2 = lstm2(pred_X2_tensor)\n",
    "\n",
    "pred_y1 = pred_y1.cpu().detach().numpy()\n",
    "pred_y2 = pred_y2.cpu().detach().numpy()\n",
    "pred_y1 = np.squeeze(pred_y1)\n",
    "pred_y2 = np.squeeze(pred_y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../results/pred_sale_volume.npy', pred_y1)\n",
    "np.save('../results/pred_wholesale_price.npy', pred_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 7, 315) (6, 7, 315)\n"
     ]
    }
   ],
   "source": [
    "# lag = 30\n",
    "# q_X = np.array([np.array(quantity_data.iloc[idx-lag:idx,]) for idx in range(lag, quantity_data.shape[0]-7, 1)])\n",
    "# q_y = np.array(quantity_data[30:-7]).T\n",
    "\n",
    "# price_data = daily_category_sales['cost_sum'] / daily_category_sales['quantity_sum']\n",
    "# price_data.fillna(0, inplace=True) \n",
    "\n",
    "# p_X = np.array([np.array(price_data.iloc[idx-lag:idx,]) for idx in range(lag, price_data.shape[0]-7, 1)])\n",
    "# p_y = np.array(price_data[30:-7]).T\n",
    "\n",
    "# print(q_X.shape, q_y.shape, p_X.shape, p_y.shape)\n",
    "\n",
    "lag = 30\n",
    "price_data = daily_category_sales['cost_sum'] / daily_category_sales['quantity_sum']\n",
    "price_data.fillna(0, inplace=True) \n",
    "\n",
    "_q_X = np.array([np.array(quantity_data.iloc[idx-lag:idx,]) for idx in range(lag, quantity_data.shape[0]-7, 1)])\n",
    "_q_y = np.array([np.array(quantity_data.iloc[idx:idx+7,]) for idx in range(lag, quantity_data.shape[0]-7, 1)])\n",
    "\n",
    "q_X_train, q_X_val, q_y_train, q_y_val = train_test_split(_q_X, _q_y, test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "_p_X = np.array([np.array(price_data.iloc[idx-lag:idx,]) for idx in range(lag, price_data.shape[0]-7, 1)])\n",
    "_p_y = np.array([np.array(price_data.iloc[idx:idx+7,]) for idx in range(lag, price_data.shape[0]-7, 1)])\n",
    "\n",
    "p_X_train, p_X_val, p_y_train, p_y_val = train_test_split(_p_X, _p_y, test_size=0.3, shuffle=True, random_state=42)\n",
    "q_y_val = q_y_val.T\n",
    "p_y_val = p_y_val.T\n",
    "print(q_y_val.shape, p_y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 7, 315) (6, 7, 315)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    q_pred_y = lstm1(torch.FloatTensor(q_X_val).to(device))\n",
    "    p_pred_y = lstm2(torch.FloatTensor(p_X_val).to(device))\n",
    "\n",
    "# q_pred_y = q_pred_y[:,0,:].cpu().detach().numpy().T\n",
    "# p_pred_y = p_pred_y[:,0,:].cpu().detach().numpy().T\n",
    "q_pred_y = q_pred_y.cpu().detach().numpy().T\n",
    "p_pred_y = p_pred_y.cpu().detach().numpy().T\n",
    "\n",
    "print(q_pred_y.shape, p_pred_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_enc =  {'Aquatic Roots and Tubers':'1', 'Cauliflower':'2' ,'Chili Peppers':'3', 'Edible Mushrooms':'4', 'Leafy Greens':'5', 'Solanaceous Vegetables':'6'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_span = range(q_y.shape[1])\n",
    "# fig, ax = plt.subplots(3,2,figsize=(20, 24), sharex=True)\n",
    "# sns.lineplot(x=t_span, y=q_y[0], ax=ax[0,0], label='True',color='green', alpha=0.8)\n",
    "# sns.lineplot(x=t_span, y=q_pred_y[0], ax=ax[0,0], label='Predicted', color='orange', alpha=0.8)\n",
    "# ax[0,0].set_title(list(categories_enc.keys())[0], fontsize=20)\n",
    "\n",
    "\n",
    "# sns.lineplot(x=t_span, y=q_y[1], ax=ax[0,1], label='True',color='green', alpha=0.8)\n",
    "# sns.lineplot(x=t_span, y=q_pred_y[1], ax=ax[0,1], label='Predicted', color='orange', alpha=0.8)\n",
    "# ax[0,1].set_title(list(categories_enc.keys())[1], fontsize=20)\n",
    "\n",
    "# sns.lineplot(x=t_span, y=q_y[2], ax=ax[1,0], label='True',color='green', alpha=0.8)\n",
    "# sns.lineplot(x=t_span, y=q_pred_y[2], ax=ax[1,0], label='Predicted', color='orange', alpha=0.8)\n",
    "# ax[1,0].set_title(list(categories_enc.keys())[2], fontsize=20)\n",
    "\n",
    "# sns.lineplot(x=t_span, y=q_y[3], ax=ax[1,1], label='True',color='green', alpha=0.8)\n",
    "# sns.lineplot(x=t_span, y=q_pred_y[3], ax=ax[1,1], label='Predicted', color='orange', alpha=0.8)\n",
    "# ax[1,1].set_title(list(categories_enc.keys())[3], fontsize=20)\n",
    "\n",
    "# sns.lineplot(x=t_span, y=q_y[4], ax=ax[2,0], label='True',color='green', alpha=0.8)\n",
    "# sns.lineplot(x=t_span, y=q_pred_y[4], ax=ax[2,0], label='Predicted', color='orange', alpha=0.8)\n",
    "# ax[2,0].set_title(list(categories_enc.keys())[4], fontsize=20)\n",
    "\n",
    "# sns.lineplot(x=t_span, y=q_y[5], ax=ax[2,1], label='True',color='green', alpha=0.8)\n",
    "# sns.lineplot(x=t_span, y=q_pred_y[5], ax=ax[2,1], label='Predicted', color='orange', alpha=0.8)\n",
    "# ax[2,1].set_title(list(categories_enc.keys())[5], fontsize=20)\n",
    "\n",
    "# ax[0,0].set_ylabel('Sales Volume', fontsize=16)\n",
    "# ax[1,0].set_ylabel('Sales Volume', fontsize=16)\n",
    "# ax[2,0].set_ylabel('Sales Volume', fontsize=16)\n",
    "# ax[2,0].set_xlabel('Time', fontsize=16)\n",
    "# ax[2,1].set_xlabel('Time', fontsize=16)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.57787449853382\n",
      "9.750038890149076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "print(math.sqrt(mean_squared_error(q_y[0], q_pred_y[0])))\n",
    "print(mean_absolute_error(q_y[0], q_pred_y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aquatic Roots and Tubers</th>\n",
       "      <td>18.46</td>\n",
       "      <td>11.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cauliflower</th>\n",
       "      <td>15.15</td>\n",
       "      <td>11.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chili Peppers</th>\n",
       "      <td>27.34</td>\n",
       "      <td>15.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edible Mushrooms</th>\n",
       "      <td>26.06</td>\n",
       "      <td>15.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leafy Greens</th>\n",
       "      <td>43.0</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solanaceous Vegetables</th>\n",
       "      <td>8.61</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Global Average</th>\n",
       "      <td>25.56</td>\n",
       "      <td>14.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           RMSE    MAE\n",
       "Aquatic Roots and Tubers  18.46  11.69\n",
       "Cauliflower               15.15  11.11\n",
       "Chili Peppers             27.34  15.98\n",
       "Edible Mushrooms          26.06  15.83\n",
       "Leafy Greens               43.0   23.6\n",
       "Solanaceous Vegetables     8.61   6.05\n",
       "Global Average            25.56  14.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aquatic Roots and Tubers</th>\n",
       "      <td>1.08</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cauliflower</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chili Peppers</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edible Mushrooms</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leafy Greens</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solanaceous Vegetables</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Global Average</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          RMSE   MAE\n",
       "Aquatic Roots and Tubers  1.08  0.64\n",
       "Cauliflower               0.58  0.37\n",
       "Chili Peppers              0.5  0.35\n",
       "Edible Mushrooms          0.85  0.63\n",
       "Leafy Greens              0.34  0.25\n",
       "Solanaceous Vegetables    0.55  0.37\n",
       "Global Average            0.69  0.43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_eval_df = pd.DataFrame(columns=['RMSE', 'MAE'], index=list(categories_enc.keys())+['Global Average'])\n",
    "p_eval_df = pd.DataFrame(columns=['RMSE', 'MAE'], index=list(categories_enc.keys())+['Global Average'])\n",
    "for i in range(6):\n",
    "    q_eval_df.iloc[i,0] = round(math.sqrt(mean_squared_error(q_y_val[i], q_pred_y[i])),2)\n",
    "    q_eval_df.iloc[i,1] = round(mean_absolute_error(q_y_val[i], q_pred_y[i]),2)\n",
    "    p_eval_df.iloc[i,0] = round(math.sqrt(mean_squared_error(p_y_val[i], p_pred_y[i])),2)\n",
    "    p_eval_df.iloc[i,1] = round(mean_absolute_error(p_y_val[i], p_pred_y[i]),2)\n",
    "\n",
    "q_eval_df.iloc[6,0] = round(math.sqrt(mean_squared_error(q_y_val.reshape(-1), q_pred_y.reshape(-1))),2)\n",
    "q_eval_df.iloc[6,1] = round(mean_absolute_error(q_y_val.reshape(-1), q_pred_y.reshape(-1)),2)\n",
    "p_eval_df.iloc[6,0] = round(math.sqrt(mean_squared_error(p_y_val.reshape(-1), p_pred_y.reshape(-1))),2)\n",
    "p_eval_df.iloc[6,1] = round(mean_absolute_error(p_y_val.reshape(-1), p_pred_y.reshape(-1)),2)\n",
    "display(q_eval_df)\n",
    "display(p_eval_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
