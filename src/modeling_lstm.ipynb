{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_name\n",
      "Aquatic Roots and Tubers     0\n",
      "Cauliflower                  1\n",
      "Chili Peppers                0\n",
      "Edible Mushrooms             0\n",
      "Leafy Greens                 0\n",
      "Solanaceous Vegetables      35\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "daily_category_sales = pd.read_csv('../data/daily_category_sales.csv', header=[0,1], index_col=0)\n",
    "data = daily_category_sales['quantity_sum'].copy()\n",
    "print(data.isna().sum())\n",
    "data.fillna(0, inplace=True) # use zero to replace NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### category sales quantity prediction: <br>use sales quantity of last N days to predict the current sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([749, 14, 6]) torch.Size([749, 6])\n"
     ]
    }
   ],
   "source": [
    "lag = 14\n",
    "X = np.array([np.array(data.iloc[idx-lag:idx,]) for idx in range(lag, data.shape[0], 1)])\n",
    "y = np.array([np.array(data.iloc[idx,]) for idx in range(lag, data.shape[0], 1)])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "\n",
    "X_tensor = torch.FloatTensor(X_train).to(device)\n",
    "y_tensor = torch.FloatTensor(y_train).to(device)\n",
    "X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "y_val_tensor = torch.FloatTensor(y_val).to(device)\n",
    "print(X_tensor.shape, y_tensor.shape)\n",
    "# (batch, seq_len, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, fc_size=24):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, fc_size)\n",
    "        self.fc2= nn.Linear(fc_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc1(out[:, -1, :])  # Take the output from the last time step\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(6, 128, num_layers=2, batch_first=True)\n",
      "  (fc1): Linear(in_features=128, out_features=24, bias=True)\n",
      "  (fc2): Linear(in_features=24, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LSTM model\n",
    "input_size = 6\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 6\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers,output_size).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Train Loss: 96.8876, Validation Loss: 95.9333\n",
      "Epoch [10/200], Train Loss: 84.5648, Validation Loss: 82.5474\n",
      "Epoch [15/200], Train Loss: 67.9945, Validation Loss: 65.8948\n",
      "Epoch [20/200], Train Loss: 55.3418, Validation Loss: 54.1174\n",
      "Epoch [25/200], Train Loss: 50.9733, Validation Loss: 49.3223\n",
      "Epoch [30/200], Train Loss: 48.8540, Validation Loss: 48.0607\n",
      "Epoch [35/200], Train Loss: 48.8507, Validation Loss: 47.9249\n",
      "Epoch [40/200], Train Loss: 48.5017, Validation Loss: 47.9224\n",
      "Epoch [45/200], Train Loss: 48.5467, Validation Loss: 47.9190\n",
      "Epoch [50/200], Train Loss: 48.5783, Validation Loss: 47.9221\n",
      "Epoch [55/200], Train Loss: 47.5570, Validation Loss: 46.1855\n",
      "Epoch [60/200], Train Loss: 40.7017, Validation Loss: 41.6644\n",
      "Epoch [65/200], Train Loss: 38.6021, Validation Loss: 39.9742\n",
      "Epoch [70/200], Train Loss: 38.5305, Validation Loss: 39.5123\n",
      "Epoch [75/200], Train Loss: 37.2117, Validation Loss: 38.8817\n",
      "Epoch [80/200], Train Loss: 37.0461, Validation Loss: 38.9446\n",
      "Epoch [85/200], Train Loss: 36.1505, Validation Loss: 38.4996\n",
      "Epoch [90/200], Train Loss: 36.3367, Validation Loss: 38.7537\n",
      "Epoch [95/200], Train Loss: 35.6026, Validation Loss: 38.3659\n",
      "Epoch [100/200], Train Loss: 35.0438, Validation Loss: 38.0053\n",
      "Epoch [105/200], Train Loss: 34.7865, Validation Loss: 38.0200\n",
      "Epoch [110/200], Train Loss: 34.7514, Validation Loss: 37.9498\n",
      "Epoch [115/200], Train Loss: 34.6180, Validation Loss: 37.7917\n",
      "Epoch [120/200], Train Loss: 34.0331, Validation Loss: 37.8778\n",
      "Epoch [125/200], Train Loss: 33.7351, Validation Loss: 37.8900\n",
      "Epoch [130/200], Train Loss: 33.6362, Validation Loss: 37.9583\n",
      "Epoch [135/200], Train Loss: 32.9540, Validation Loss: 37.9225\n",
      "Epoch [140/200], Train Loss: 33.3212, Validation Loss: 37.8846\n",
      "Epoch [145/200], Train Loss: 32.9760, Validation Loss: 37.8645\n",
      "Epoch [150/200], Train Loss: 32.8868, Validation Loss: 38.1956\n",
      "Epoch [155/200], Train Loss: 31.6329, Validation Loss: 38.1288\n",
      "Epoch [160/200], Train Loss: 31.7157, Validation Loss: 38.7148\n",
      "Epoch [165/200], Train Loss: 31.2848, Validation Loss: 38.3352\n",
      "Epoch [170/200], Train Loss: 30.1881, Validation Loss: 38.4169\n",
      "Epoch [175/200], Train Loss: 29.6118, Validation Loss: 38.8309\n",
      "Epoch [180/200], Train Loss: 29.1533, Validation Loss: 38.8941\n",
      "Epoch [185/200], Train Loss: 28.6254, Validation Loss: 39.2608\n",
      "Epoch [190/200], Train Loss: 28.6301, Validation Loss: 38.8859\n",
      "Epoch [195/200], Train Loss: 27.9990, Validation Loss: 39.2043\n",
      "Epoch [200/200], Train Loss: 27.3170, Validation Loss: 39.4290\n"
     ]
    }
   ],
   "source": [
    "# load data in batches\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "batch_size = 128\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "n_batch = math.ceil(X_tensor.shape[0] / batch_size)\n",
    "\n",
    "\n",
    "# train\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = 0\n",
    "    model.train()\n",
    "    for X_batch, y_batch in data_loader:\n",
    "        # forward pass\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        # Compute the RMSE loss\n",
    "        loss = torch.sqrt(criterion(outputs, y_batch))\n",
    "\n",
    "        # backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item() / n_batch\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = torch.sqrt(criterion(val_outputs, y_val_tensor))\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "# Test the model on new data (you can replace this with your own test data)\n",
    "# test_input = torch.FloatTensor(np.random.rand(10, m, t))\n",
    "# with torch.no_grad():\n",
    "#     predicted_output = model(test_input)\n",
    "\n",
    "# Print the predicted output\n",
    "# print(\"Predicted Output:\")\n",
    "# print(predicted_output.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"input_size\": input_size,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"output_size\": output_size,\n",
    "    \"fc_size\": 24\n",
    "}\n",
    "\n",
    "with open('../model/lstm_config.json', 'w') as f:\n",
    "    json.dump(model_config, f)\n",
    "\n",
    "torch.save(model.state_dict(),'../model/lstm_for_category_sales.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
